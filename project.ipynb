{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Load the data (images shape: 7000 x 28 x 28, labels shape: 7000)\n"
      ],
      "metadata": {
        "id": "A9EwZuEhMtdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjcCLd2D5_e8",
        "outputId": "0b504acd-974d-456a-e8d4-946ccf5ff9a6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.7.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.16.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras) (25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras) (4.14.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "uEthHdq_LCSd"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Sequential, Model, Input\n",
        "from keras import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
        "import numpy as np\n",
        "import pickle as pk\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras import models, layers\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('input_data.pkl', 'rb') as f:\n",
        "    dd = pk.load(f)\n",
        "\n",
        "data = dd['data']\n",
        "labels = dd['labels']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data, labels,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n"
      ],
      "metadata": {
        "id": "5YEHS-YOMaRJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3386c9ad-1883-483e-c010-fb40bfb8d0c6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5600, 28, 28) (5600,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "data is (7000, 28, 28), label is a 1D vector with 7000 values\n",
        "\n",
        "CHANGE: Instead of no preprocessing, a minMaxScaler would be better on the pixels (between 0 and 1)\n",
        "but could simply divide by 255 every value, same effect!"
      ],
      "metadata": {
        "id": "NRxs8o7umPM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "plt.imshow(X_train[0].squeeze(), cmap='gray')\n",
        "print(f\"np.max(X_train[0]):{np.max(X_train[0])}\")"
      ],
      "metadata": {
        "id": "hyOs2n52MfCu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "4f9bebb0-9c79-4bd4-d181-0d927c39cbec"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "np.max(X_train[0]):1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAITFJREFUeJzt3X9sVfX9x/HXbaG3FNpbSmlvL5RaEIryo4sMayMijgboFgNKFn/9Ac7AdMUMmdN0UdFtSTeW+DUuDLPEgS7ir0QgmIVFkZapBW0RGcoq7aot0BYotLc/6A/a8/2DrHqBQj/H237a8nwkJ6H33hfnzemBVw/33s/1OI7jCACAARZhewAAwLWJAgIAWEEBAQCsoIAAAFZQQAAAKyggAIAVFBAAwAoKCABgxQjbA1ysu7tbJ06cUGxsrDwej+1xAACGHMdRU1OTAoGAIiJ6v84ZdAV04sQJpaam2h4DAPA9VVdXa+LEib3eP+gKKDY21vYIGGTcXAmPHz/e1b6u9NNab3w+n3HGzZ+pqanJOHPq1CnjjCR1dHS4ygHfdbV/z/vtOaCNGzfquuuuU3R0tLKysvTJJ5/0Kcd/u+FiHo/HeIuIiBiwLTIyckA2N7O5OXb8HUS4XO1c6pcCevPNN7Vu3TqtX79eBw4cUGZmphYvXqyTJ0/2x+4AAENQvxTQ888/r1WrVunBBx/UjTfeqJdeekkxMTH629/+1h+7AwAMQWEvoI6ODpWWlionJ+fbnUREKCcnR8XFxZc8vr29XcFgMGQDAAx/YS+g06dPq6urS8nJySG3Jycnq7a29pLHFxQUyOfz9Wy8Ag4Arg3W34ian5+vxsbGnq26utr2SACAARD2l2EnJiYqMjJSdXV1IbfX1dXJ7/df8niv1yuv1xvuMQAAg1zYr4CioqI0Z84c7d69u+e27u5u7d69W9nZ2eHeHQBgiOqXN6KuW7dOK1as0A9/+EPdfPPNeuGFF9TS0qIHH3ywP3YHABiC+qWA7rnnHp06dUrPPPOMamtr9YMf/EC7du265IUJAIBrl8dxHMf2EN8VDAZdLW2CoSEhIcE4M3XqVOOM2+cVR48ebZxpbGw0zrg5x0eMGLiVs1JSUowzf/3rX/thEgxljY2NiouL6/V+66+CAwBcmyggAIAVFBAAwAoKCABgBQUEALCCAgIAWEEBAQCsoIAAAFZQQAAAKyggAIAVFBAAwAoKCABgxcCtbghImj9/vnHm3Llzxpljx44ZZyR3i5i6+Rj5iz+wsS+utKhjb+Lj440zklRbW2ucGTt2rHHm7NmzxpmB5PF4jDODbH3nQY0rIACAFRQQAMAKCggAYAUFBACwggICAFhBAQEArKCAAABWUEAAACsoIACAFRQQAMAKCggAYAUFBACwggICAFjBatjDzGBfvberq8s4k5SUZJxpbm42zkhSZWWlcaa1tdU4EwgEjDNu7Nmzx1Vu3Lhxxplp06YZZ/bv32+cGUisbN2/uAICAFhBAQEArKCAAABWUEAAACsoIACAFRQQAMAKCggAYAUFBACwggICAFhBAQEArKCAAABWUEAAACtYjHSYGcjFE2NiYgYkc/78eeOM3+83zkhSXV2dcSYqKso4M2HCBONMSUmJccat0aNHG2cG6ji4+R65OYfQ/7gCAgBYQQEBAKyggAAAVlBAAAArKCAAgBUUEADACgoIAGAFBQQAsIICAgBYQQEBAKyggAAAVlBAAAArWIx0mElISDDOLFq0yNW+ysvLjTMff/yxceauu+4yzrhZGFOSKioqjDNuFoCdNm2acea///2vceabb74xzkjujl9EhPnPs7GxscaZlJQU48xXX31lnJGkYDDoKoe+4QoIAGAFBQQAsCLsBfTss8/K4/GEbNOnTw/3bgAAQ1y/PAc0Y8YMvf/++9/uZARPNQEAQvVLM4wYMcL1J1ICAK4N/fIc0NGjRxUIBDR58mQ98MADqqqq6vWx7e3tCgaDIRsAYPgLewFlZWVpy5Yt2rVrlzZt2qTKykrddtttampquuzjCwoK5PP5erbU1NRwjwQAGITCXkC5ubn66U9/qtmzZ2vx4sX6xz/+oYaGBr311luXfXx+fr4aGxt7turq6nCPBAAYhPr91QHx8fGaNm1ar29a9Hq98nq9/T0GAGCQ6ff3ATU3N6uiosLVu5cBAMNX2Avo8ccfV1FRkb7++mt9/PHHuuuuuxQZGan77rsv3LsCAAxhYf8vuGPHjum+++5TfX29xo8fr3nz5mnfvn0aP358uHcFABjCPI6blRT7UTAYlM/nsz3GkJWVlWWcaWhocLWvkydPGmfS0tKMM21tbcaZ6Oho44wkdXd3G2fq6+uNM24W4XSz2KfbF/W4+YHxzJkzxpk5c+YYZ9ysrFJSUmKckaT9+/e7yuGCxsZGxcXF9Xo/a8EBAKyggAAAVlBAAAArKCAAgBUUEADACgoIAGAFBQQAsIICAgBYQQEBAKyggAAAVlBAAAArKCAAgBX9/oF0GFiRkZHGmdmzZ7va16effmqciYmJMc64WYx07NixxhlJOnjwoHEmIyPDOOPm+9Te3m6caWlpMc5I7v5Mfr/fOHPq1CnjTGlpqXFmypQpxhn0P66AAABWUEAAACsoIACAFRQQAMAKCggAYAUFBACwggICAFhBAQEArKCAAABWUEAAACsoIACAFRQQAMAKCggAYAWrYQ8ziYmJxpkzZ84M2L46OjqMM/PmzTPOuFnVWpKioqKMM83NzcaZ5ORk48zPfvYz48zLL79snJGkjz76yDgzd+5cV/sylZ2dbZxxs+q2JI0YYf5P5Pnz513t61rEFRAAwAoKCABgBQUEALCCAgIAWEEBAQCsoIAAAFZQQAAAKyggAIAVFBAAwAoKCABgBQUEALCCAgIAWMFipIOYm4UQ6+vrjTNNTU3GGUn6yU9+Ypx55ZVXjDP//ve/jTM///nPjTOSlJmZaZx56KGHjDPl5eXGGTeLfR44cMA4I0kej8c4ExFh/vPsLbfcYpxxs9hnRkaGcUaSSkpKXOXQN1wBAQCsoIAAAFZQQAAAKyggAIAVFBAAwAoKCABgBQUEALCCAgIAWEEBAQCsoIAAAFZQQAAAKyggAIAVHsdxHNtDfFcwGJTP57M9xqDgZnHHefPmGWfcLPYpSffee69xprm52Tizc+dO48yMGTOMM5JUV1dnnPF6vcaZcePGGWfcLGDq5nhLUmJionEmLS3NODNz5kzjjJvzwa1Tp04ZZ1paWvphkqGpsbFRcXFxvd7PFRAAwAoKCABghXEB7d27V3feeacCgYA8Ho+2b98ecr/jOHrmmWeUkpKiUaNGKScnR0ePHg3XvACAYcK4gFpaWpSZmamNGzde9v4NGzboxRdf1EsvvaT9+/dr9OjRWrx4sdra2r73sACA4cP4Izdzc3OVm5t72fscx9ELL7ygp556SkuXLpUkvfrqq0pOTtb27dtdPWkNABiewvocUGVlpWpra5WTk9Nzm8/nU1ZWloqLiy+baW9vVzAYDNkAAMNfWAuotrZWkpScnBxye3Jycs99FysoKJDP5+vZUlNTwzkSAGCQsv4quPz8fDU2NvZs1dXVtkcCAAyAsBaQ3++XdOmb+erq6nruu5jX61VcXFzIBgAY/sJaQOnp6fL7/dq9e3fPbcFgUPv371d2dnY4dwUAGOKMXwXX3NwcsiRIZWWlDh48qISEBE2aNElr167V73//e02dOlXp6el6+umnFQgEtGzZsnDODQAY4owLqKSkRHfccUfP1+vWrZMkrVixQlu2bNETTzyhlpYWrV69Wg0NDZo3b5527dql6Ojo8E0NABjyWIx0EHOzIOR1111nnGloaDDOSNJ9991nnHGz8Glvzx9eyZtvvmmckaSzZ88aZzIyMowzN954o3HGzVsU9uzZY5yRpEmTJhlnJk6caJxJSUkxztTU1BhnRo4caZyRpM8//9w4c+bMGVf7Go5YjBQAMChRQAAAKyggAIAVFBAAwAoKCABgBQUEALCCAgIAWEEBAQCsoIAAAFZQQAAAKyggAIAVFBAAwAoKCABghfHHMWDgeDwe44ybla3HjBljnJHcrUrc0tJinPn444+NM4FAwDgjSSNGmP+VcLPScmFhoXFm1qxZxhm339uICPOfTZubm40zR44cMc4kJCQYZ9yeD2VlZa5y6BuugAAAVlBAAAArKCAAgBUUEADACgoIAGAFBQQAsIICAgBYQQEBAKyggAAAVlBAAAArKCAAgBUUEADAChYjHcRaW1uNMxMmTDDOnDlzxjgjSTt27DDO5ObmGmeampqMM26OneRuEc7u7m7jTHJysnGmvLzcOBMfH2+ckaS2tjbjzNixY40zx48fN864WYx0z549xhlJioqKcpVD33AFBACwggICAFhBAQEArKCAAABWUEAAACsoIACAFRQQAMAKCggAYAUFBACwggICAFhBAQEArKCAAABWsBjpIJaWlmac6ejoMM5kZGQYZySpurraONPS0mKcmTdvnnHmX//6l3FGkhoaGowzbhYWnTt3rnHmyJEjxpnS0lLjjORuvhkzZhhnqqqqjDNuFgh1M5skHTp0yFUOfcMVEADACgoIAGAFBQQAsIICAgBYQQEBAKyggAAAVlBAAAArKCAAgBUUEADACgoIAGAFBQQAsIICAgBYwWKkg1h3d7dxxs1ipG4WCJWkyspK48yUKVOMM1999ZVxZsQId6f2qFGjBiTz6aefGmfi4uKMM52dncYZSWprazPOfPHFF8aZU6dOGWccxzHOuFkwVpLGjx9vnKmrq3O1r2sRV0AAACsoIACAFcYFtHfvXt15550KBALyeDzavn17yP0rV66Ux+MJ2ZYsWRKueQEAw4RxAbW0tCgzM1MbN27s9TFLlixRTU1Nz/b6669/ryEBAMOP8TO1ubm5ys3NveJjvF6v/H6/66EAAMNfvzwHVFhYqKSkJGVkZOiRRx5RfX19r49tb29XMBgM2QAAw1/YC2jJkiV69dVXtXv3bv3xj39UUVGRcnNz1dXVddnHFxQUyOfz9WypqanhHgkAMAiF/X1A9957b8+vZ82apdmzZ2vKlCkqLCzUwoULL3l8fn6+1q1b1/N1MBikhADgGtDvL8OePHmyEhMTVV5eftn7vV6v4uLiQjYAwPDX7wV07Ngx1dfXKyUlpb93BQAYQoz/C665uTnkaqayslIHDx5UQkKCEhIS9Nxzz2n58uXy+/2qqKjQE088oeuvv16LFy8O6+AAgKHNuIBKSkp0xx139Hz9v+dvVqxYoU2bNunQoUN65ZVX1NDQoEAgoEWLFul3v/udvF5v+KYGAAx5xgW0YMGCKy4G+M9//vN7DYRvtba2GmdiYmKMM2fOnDHOSBdeQm+qt1dDXombxR3dLMoqSdHR0cYZN4ulullQMyEhwTgzZswY44ykXp+zvZLExERX+zLl5rwrKSlxtS+3i7mib1gLDgBgBQUEALCCAgIAWEEBAQCsoIAAAFZQQAAAKyggAIAVFBAAwAoKCABgBQUEALCCAgIAWEEBAQCsoIAAAFaE/SO5ET6BQMA4c/r0aeOM3+83zkjSyJEjjTNuVpvOysoyznz++efGGUk6ceKEcWbevHnGme7ubuPM8ePHjTMNDQ3GGUnKzMw0zrhZrdvNqttuV/h245tvvhmwfV2LuAICAFhBAQEArKCAAABWUEAAACsoIACAFRQQAMAKCggAYAUFBACwggICAFhBAQEArKCAAABWUEAAACtYjHQQO3/+vHGmo6PDONPc3GyckaTOzk7jTGRkpHGmvr7eOBMR4e5nKzfzVVZWGmduuOEG44wbbW1trnLBYNA4ExMTY5xJTk42zrj5M82aNcs4I0lnz551lUPfcAUEALCCAgIAWEEBAQCsoIAAAFZQQAAAKyggAIAVFBAAwAoKCABgBQUEALCCAgIAWEEBAQCsoIAAAFawGOkg1tDQYJxJSEgYkP1I0tixY40zLS0txhk3i33GxsYaZyQpKirKOONmccz9+/cbZ9ws9un1eo0zknTy5EnjTG1trXFm/vz5xpmqqirjzIEDB4wzktTe3u4qh77hCggAYAUFBACwggICAFhBAQEArKCAAABWUEAAACsoIACAFRQQAMAKCggAYAUFBACwggICAFhBAQEArGAx0kHs+uuvN85UV1cbZ0aMcHcaJCUlGWdSUlJc7cuU2wVWPR6PcWbq1KnGmS+++MI4Ex0dbZxx8+eRpAkTJhhnmpubjTM7d+40zsybN8844/Z8QP/iCggAYAUFBACwwqiACgoKNHfuXMXGxiopKUnLli1TWVlZyGPa2tqUl5encePGacyYMVq+fLnq6urCOjQAYOgzKqCioiLl5eVp3759eu+999TZ2alFixaFfMjYY489pp07d+rtt99WUVGRTpw4obvvvjvsgwMAhjajZ5937doV8vWWLVuUlJSk0tJSzZ8/X42NjXr55Ze1detW/ehHP5Ikbd68WTfccIP27dunW265JXyTAwCGtO/1HFBjY6Okbz8GurS0VJ2dncrJyel5zPTp0zVp0iQVFxdf9vdob29XMBgM2QAAw5/rAuru7tbatWt16623aubMmZIufCZ8VFSU4uPjQx6bnJzc6+fFFxQUyOfz9WypqaluRwIADCGuCygvL0+HDx/WG2+88b0GyM/PV2NjY8/m5n0sAIChx9U7ENesWaN3331Xe/fu1cSJE3tu9/v96ujoUENDQ8hVUF1dnfx+/2V/L6/XK6/X62YMAMAQZnQF5DiO1qxZo23btumDDz5Qenp6yP1z5szRyJEjtXv37p7bysrKVFVVpezs7PBMDAAYFoyugPLy8rR161bt2LFDsbGxPc/r+Hw+jRo1Sj6fTw899JDWrVunhIQExcXF6dFHH1V2djavgAMAhDAqoE2bNkmSFixYEHL75s2btXLlSknS//3f/ykiIkLLly9Xe3u7Fi9erL/85S9hGRYAMHwYFZDjOFd9THR0tDZu3KiNGze6HgoXnD592jjT3t7eD5Nc3nef/+urr7/+2jiTkZFhnNm3b59xRpK6urqMMx0dHcaZpUuXGmf27NljnGltbTXOSH37u36xzMxM48zx48eNM26+R999a4iJv//9765y6BvWggMAWEEBAQCsoIAAAFZQQAAAKyggAIAVFBAAwAoKCABgBQUEALCCAgIAWEEBAQCsoIAAAFZQQAAAKyggAIAVrj4RFQOjoaHBODNu3DjjTH19vXFGkkaPHm2ccbPC95dffmmc6ezsNM5ICvkk375yc/yKi4uNMyNGmP91HTNmjHFGcreq+sGDB40zSUlJxpmzZ88aZyorK40zknT+/HlXOfQNV0AAACsoIACAFRQQAMAKCggAYAUFBACwggICAFhBAQEArKCAAABWUEAAACsoIACAFRQQAMAKCggAYAWLkQ5i2dnZxpnPP//cOBMZGWmckQZuMVI3C2O6WVRUkjwej3Gmra3NOBMTE2OcaWlpMc6kpaUZZyTp3LlzrnKmurq6jDPJycnGGTcL+0pSSkqKcaaurs7Vvq5FXAEBAKyggAAAVlBAAAArKCAAgBUUEADACgoIAGAFBQQAsIICAgBYQQEBAKyggAAAVlBAAAArKCAAgBUsRjqIHTlyxDgzatQo44ybxT4lKRgMGmfOnDljnImOjjbOuFnk0i03i7m6OXbd3d0DkpGkqKgo44ybRVkHSmJioqtcTU1NmCfBd3EFBACwggICAFhBAQEArKCAAABWUEAAACsoIACAFRQQAMAKCggAYAUFBACwggICAFhBAQEArKCAAABWsBjpINbc3GycGTdunHHG7WKk48ePN85MnDjROFNYWGiccTObJEVEmP9M5mYxUjeLxrpZWNTt99ZNbvTo0a72ZcrNQrMNDQ2u9uU2h77hCggAYAUFBACwwqiACgoKNHfuXMXGxiopKUnLli1TWVlZyGMWLFggj8cTsj388MNhHRoAMPQZFVBRUZHy8vK0b98+vffee+rs7NSiRYvU0tIS8rhVq1appqamZ9uwYUNYhwYADH1GL0LYtWtXyNdbtmxRUlKSSktLNX/+/J7bY2Ji5Pf7wzMhAGBY+l7PATU2NkqSEhISQm5/7bXXlJiYqJkzZyo/P1+tra29/h7t7e0KBoMhGwBg+HP9Muzu7m6tXbtWt956q2bOnNlz+/3336+0tDQFAgEdOnRITz75pMrKyvTOO+9c9vcpKCjQc88953YMAMAQ5bqA8vLydPjwYX344Ycht69evbrn17NmzVJKSooWLlyoiooKTZky5ZLfJz8/X+vWrev5OhgMKjU11e1YAIAhwlUBrVmzRu+++6727t171TcWZmVlSZLKy8svW0Ber1der9fNGACAIcyogBzH0aOPPqpt27apsLBQ6enpV80cPHhQkpSSkuJqQADA8GRUQHl5edq6dat27Nih2NhY1dbWSpJ8Pp9GjRqliooKbd26VT/+8Y81btw4HTp0SI899pjmz5+v2bNn98sfAAAwNBkV0KZNmyRdeLPpd23evFkrV65UVFSU3n//fb3wwgtqaWlRamqqli9frqeeeipsAwMAhgfj/4K7ktTUVBUVFX2vgQAA1wZWwx7E3KzMHB0dbZxxs7qw5G7F5IyMDOPMyZMnjTPx8fHGGUmXrOrRF25eROPxeIwzbpw/f95Vzs3K2x0dHcaZtrY244ybY3fTTTcZZySpoqLCVQ59w2KkAAArKCAAgBUUEADACgoIAGAFBQQAsIICAgBYQQEBAKyggAAAVlBAAAArKCAAgBUUEADACgoIAGCFx7naEtcDLBgMyufz2R5jUAgEAsaZhIQE48zx48eNM5J09uxZVzng+3Bzjt9+++2u9lVaWmqcqaqqcrWv4aixsVFxcXG93s8VEADACgoIAGAFBQQAsIICAgBYQQEBAKyggAAAVlBAAAArKCAAgBUUEADACgoIAGAFBQQAsGKE7QEuNsiWprOqu7vbONPV1WWc4ZhjKHFzvnZ2drral5u/g/jW1b5Xg24x0mPHjik1NdX2GACA76m6uloTJ07s9f5BV0Dd3d06ceKEYmNj5fF4Qu4LBoNKTU1VdXX1FVdYHe44DhdwHC7gOFzAcbhgMBwHx3HU1NSkQCCgiIjen+kZdP8FFxERccXGlKS4uLhr+gT7H47DBRyHCzgOF3AcLrB9HPrysTq8CAEAYAUFBACwYkgVkNfr1fr16+X1em2PYhXH4QKOwwUchws4DhcMpeMw6F6EAAC4NgypKyAAwPBBAQEArKCAAABWUEAAACuGTAFt3LhR1113naKjo5WVlaVPPvnE9kgD7tlnn5XH4wnZpk+fbnusfrd3717deeedCgQC8ng82r59e8j9juPomWeeUUpKikaNGqWcnBwdPXrUzrD96GrHYeXKlZecH0uWLLEzbD8pKCjQ3LlzFRsbq6SkJC1btkxlZWUhj2lra1NeXp7GjRunMWPGaPny5aqrq7M0cf/oy3FYsGDBJefDww8/bGniyxsSBfTmm29q3bp1Wr9+vQ4cOKDMzEwtXrxYJ0+etD3agJsxY4Zqamp6tg8//ND2SP2upaVFmZmZ2rhx42Xv37Bhg1588UW99NJL2r9/v0aPHq3Fixerra1tgCftX1c7DpK0ZMmSkPPj9ddfH8AJ+19RUZHy8vK0b98+vffee+rs7NSiRYvU0tLS85jHHntMO3fu1Ntvv62ioiKdOHFCd999t8Wpw68vx0GSVq1aFXI+bNiwwdLEvXCGgJtvvtnJy8vr+bqrq8sJBAJOQUGBxakG3vr1653MzEzbY1glydm2bVvP193d3Y7f73f+9Kc/9dzW0NDgeL1e5/XXX7cw4cC4+Dg4juOsWLHCWbp0qZV5bDl58qQjySkqKnIc58L3fuTIkc7bb7/d85gjR444kpzi4mJbY/a7i4+D4zjO7bff7vzyl7+0N1QfDPoroI6ODpWWlionJ6fntoiICOXk5Ki4uNjiZHYcPXpUgUBAkydP1gMPPKCqqirbI1lVWVmp2trakPPD5/MpKyvrmjw/CgsLlZSUpIyMDD3yyCOqr6+3PVK/amxslCQlJCRIkkpLS9XZ2RlyPkyfPl2TJk0a1ufDxcfhf1577TUlJiZq5syZys/PV2trq43xejXoFiO92OnTp9XV1aXk5OSQ25OTk/Wf//zH0lR2ZGVlacuWLcrIyFBNTY2ee+453XbbbTp8+LBiY2Ntj2dFbW2tJF32/PjffdeKJUuW6O6771Z6eroqKir0m9/8Rrm5uSouLlZkZKTt8cKuu7tba9eu1a233qqZM2dKunA+REVFKT4+PuSxw/l8uNxxkKT7779faWlpCgQCOnTokJ588kmVlZXpnXfesThtqEFfQPhWbm5uz69nz56trKwspaWl6a233tJDDz1kcTIMBvfee2/Pr2fNmqXZs2drypQpKiws1MKFCy1O1j/y8vJ0+PDha+J50Cvp7TisXr2659ezZs1SSkqKFi5cqIqKCk2ZMmWgx7ysQf9fcImJiYqMjLzkVSx1dXXy+/2Wphoc4uPjNW3aNJWXl9sexZr/nQOcH5eaPHmyEhMTh+X5sWbNGr377rvas2dPyMe3+P1+dXR0qKGhIeTxw/V86O04XE5WVpYkDarzYdAXUFRUlObMmaPdu3f33Nbd3a3du3crOzvb4mT2NTc3q6KiQikpKbZHsSY9PV1+vz/k/AgGg9q/f/81f34cO3ZM9fX1w+r8cBxHa9as0bZt2/TBBx8oPT095P45c+Zo5MiRIedDWVmZqqqqhtX5cLXjcDkHDx6UpMF1Pth+FURfvPHGG47X63W2bNnifPnll87q1aud+Ph4p7a21vZoA+pXv/qVU1hY6FRWVjofffSRk5OT4yQmJjonT560PVq/ampqcj777DPns88+cyQ5zz//vPPZZ58533zzjeM4jvOHP/zBiY+Pd3bs2OEcOnTIWbp0qZOenu6cO3fO8uThdaXj0NTU5Dz++ONOcXGxU1lZ6bz//vvOTTfd5EydOtVpa2uzPXrYPPLII47P53MKCwudmpqanq21tbXnMQ8//LAzadIk54MPPnBKSkqc7OxsJzs72+LU4Xe141BeXu789re/dUpKSpzKykpnx44dzuTJk5358+dbnjzUkCggx3GcP//5z86kSZOcqKgo5+abb3b27dtne6QBd8899zgpKSlOVFSUM2HCBOeee+5xysvLbY/V7/bs2eNIumRbsWKF4zgXXor99NNPO8nJyY7X63UWLlzolJWV2R26H1zpOLS2tjqLFi1yxo8f74wcOdJJS0tzVq1aNex+SLvcn1+Ss3nz5p7HnDt3zvnFL37hjB071omJiXHuuusup6amxt7Q/eBqx6GqqsqZP3++k5CQ4Hi9Xuf66693fv3rXzuNjY12B78IH8cAALBi0D8HBAAYniggAIAVFBAAwAoKCABgBQUEALCCAgIAWEEBAQCsoIAAAFZQQAAAKyggAIAVFBAAwAoKCABgxf8DaP6QKAe/er8AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "print(f\"X_train.shape:{X_train.shape}\")\n",
        "print(f\"X_test.shape:{X_test.shape}\")\n",
        "print(f\"np.max(X_train):{np.max(X_train)}, np.min(X_train):{np.min(X_train)}\")"
      ],
      "metadata": {
        "id": "nP3kEIqCMh2C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "691f4a17-e607-405c-86ca-618dd1504799"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train.shape:(5600, 28, 28, 1)\n",
            "X_test.shape:(1400, 28, 28, 1)\n",
            "np.max(X_train):1.0, np.min(X_train):0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = len(np.unique(y_train))\n",
        "input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
        "print(f\"n_classes:{n_classes}, input_shape:{input_shape}\")"
      ],
      "metadata": {
        "id": "w9Ul_YRYMm8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ede4973f-d80e-42c2-f4ae-e34f4346d9dc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_classes:10, input_shape:(28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CHANGE: instead of searching from 4 to 10 (kernel size), i chose to tighten the bound to 5, 7, 9, which would save me a lot of time. not that big of a change, just faster. + ANOTHER CHANGE: instead of using grid search, i decided to use a separate CNN to find the optimal kernel size, so that on each iteration i wouldnt have to wait for the kernel size to be decided. this cnn says the best results are obtained with 5x5, and so from this point i used the 5x5 kernel."
      ],
      "metadata": {
        "id": "55mTk84-o5ZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_sizes = [5, 7, 9]  # Test these kernel sizes\n",
        "best_accuracy = 0\n",
        "best_model = None\n",
        "best_kernel = None\n",
        "\n",
        "for k_size in kernel_sizes:\n",
        "    print(f\"Testing kernel size: {k_size}x{k_size}\")\n",
        "\n",
        "    model = Sequential([\n",
        "        Conv2D(64, kernel_size=(k_size, k_size),\n",
        "               input_shape=input_shape,\n",
        "               padding='same',\n",
        "               activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "        layers.Dense(128, activation=\"relu\"),  # expand\n",
        "        layers.Dense(256, activation=\"relu\"),  # expand more\n",
        "        layers.Dense(128, activation=\"relu\"),  # contract\n",
        "        layers.Dense(64, activation=\"relu\"),   # contract more\n",
        "        layers.Dense(10, activation=\"softmax\") # output layer\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(X_train, y_train,\n",
        "                       batch_size=64,\n",
        "                       epochs=10,\n",
        "                       verbose=1,\n",
        "                       validation_data=(X_test, y_test))\n",
        "\n",
        "    val_acc = max(history.history['val_accuracy'])\n",
        "    if val_acc > best_accuracy:\n",
        "        best_accuracy = val_acc\n",
        "        best_kernel = k_size\n",
        "        best_model = model\n",
        "        print(f\"New best kernel: {k_size}x{k_size} with accuracy: {val_acc:.4f}\")\n",
        "\n",
        "\n",
        "print(f\"\\nSaved best model with kernel size {best_kernel}x{best_kernel} \")"
      ],
      "metadata": {
        "id": "iuGKd157NBsy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "513f8498-b1e1-4357-9548-5e4a7afb5279"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing kernel size: 5x5\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.5294 - loss: 1.2785 - val_accuracy: 0.7850 - val_loss: 0.6121\n",
            "Epoch 2/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8125 - loss: 0.5254 - val_accuracy: 0.8257 - val_loss: 0.4883\n",
            "Epoch 3/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8480 - loss: 0.4192 - val_accuracy: 0.8386 - val_loss: 0.4621\n",
            "Epoch 4/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8732 - loss: 0.3530 - val_accuracy: 0.8364 - val_loss: 0.4438\n",
            "Epoch 5/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8882 - loss: 0.3042 - val_accuracy: 0.8414 - val_loss: 0.4608\n",
            "Epoch 6/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9078 - loss: 0.2544 - val_accuracy: 0.8614 - val_loss: 0.3964\n",
            "Epoch 7/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9269 - loss: 0.2110 - val_accuracy: 0.8593 - val_loss: 0.4379\n",
            "Epoch 8/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9243 - loss: 0.2225 - val_accuracy: 0.8471 - val_loss: 0.4499\n",
            "Epoch 9/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9347 - loss: 0.1830 - val_accuracy: 0.8600 - val_loss: 0.4147\n",
            "Epoch 10/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.1517 - val_accuracy: 0.8700 - val_loss: 0.4301\n",
            "New best kernel: 5x5 with accuracy: 0.8700\n",
            "Testing kernel size: 7x7\n",
            "Epoch 1/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.5012 - loss: 1.3156 - val_accuracy: 0.7793 - val_loss: 0.6080\n",
            "Epoch 2/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7960 - loss: 0.5625 - val_accuracy: 0.8043 - val_loss: 0.5186\n",
            "Epoch 3/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8370 - loss: 0.4543 - val_accuracy: 0.8393 - val_loss: 0.4526\n",
            "Epoch 4/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8656 - loss: 0.3762 - val_accuracy: 0.8579 - val_loss: 0.4216\n",
            "Epoch 5/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8823 - loss: 0.3304 - val_accuracy: 0.8479 - val_loss: 0.4323\n",
            "Epoch 6/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8933 - loss: 0.3025 - val_accuracy: 0.8543 - val_loss: 0.4277\n",
            "Epoch 7/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9048 - loss: 0.2673 - val_accuracy: 0.8514 - val_loss: 0.4149\n",
            "Epoch 8/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9230 - loss: 0.2254 - val_accuracy: 0.8586 - val_loss: 0.3994\n",
            "Epoch 9/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9258 - loss: 0.1985 - val_accuracy: 0.8536 - val_loss: 0.4719\n",
            "Epoch 10/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9317 - loss: 0.1894 - val_accuracy: 0.8614 - val_loss: 0.4298\n",
            "Testing kernel size: 9x9\n",
            "Epoch 1/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.5151 - loss: 1.3012 - val_accuracy: 0.7893 - val_loss: 0.6079\n",
            "Epoch 2/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8037 - loss: 0.5318 - val_accuracy: 0.8186 - val_loss: 0.4989\n",
            "Epoch 3/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8342 - loss: 0.4400 - val_accuracy: 0.8307 - val_loss: 0.4744\n",
            "Epoch 4/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8586 - loss: 0.3812 - val_accuracy: 0.8493 - val_loss: 0.4295\n",
            "Epoch 5/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8750 - loss: 0.3404 - val_accuracy: 0.8421 - val_loss: 0.4185\n",
            "Epoch 6/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8838 - loss: 0.3175 - val_accuracy: 0.8336 - val_loss: 0.4397\n",
            "Epoch 7/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8987 - loss: 0.2754 - val_accuracy: 0.8471 - val_loss: 0.4182\n",
            "Epoch 8/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9085 - loss: 0.2539 - val_accuracy: 0.8536 - val_loss: 0.4175\n",
            "Epoch 9/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9323 - loss: 0.1934 - val_accuracy: 0.8414 - val_loss: 0.4608\n",
            "Epoch 10/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9254 - loss: 0.2076 - val_accuracy: 0.8486 - val_loss: 0.4802\n",
            "\n",
            "Saved best model with kernel size 5x5 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5x5 turned out to be the best! so will use 5X5 kernel (1 convolution)."
      ],
      "metadata": {
        "id": "GjRyRWMCq43q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv_model = models.Sequential([\n",
        "    layers.Conv2D(32, (5, 5), activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "])\n",
        "best_model.compile(optimizer='adam',\n",
        "                   loss='sparse_categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "best_model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=1)"
      ],
      "metadata": {
        "id": "gJyJvo4jatfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f03f191e-54ca-4c0f-986c-f9963079592b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9312 - loss: 0.1863\n",
            "Epoch 2/5\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9472 - loss: 0.1488\n",
            "Epoch 3/5\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9627 - loss: 0.1018\n",
            "Epoch 4/5\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9666 - loss: 0.0906\n",
            "Epoch 5/5\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9651 - loss: 0.0965\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79ea05065cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_model = Sequential([\n",
        "    layers.Input(shape=(conv_model.output_shape[1],)),\n",
        "    layers.Dense(128, activation=\"relu\"),\n",
        "    layers.Dense(256, activation=\"relu\"),\n",
        "    layers.Dense(128, activation=\"relu\"),\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "YvCJJ4_RNGed"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(28, 28, 1))\n",
        "x = conv_model(inputs)\n",
        "outputs = mlp_model(x)\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_test, y_test)\n",
        ")\n"
      ],
      "metadata": {
        "id": "e52LH5kAxtNS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77840463-e5a7-4bb5-8a6b-0718e481614a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.5252 - loss: 1.3256 - val_accuracy: 0.7529 - val_loss: 0.6480\n",
            "Epoch 2/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7783 - loss: 0.5853 - val_accuracy: 0.8121 - val_loss: 0.5003\n",
            "Epoch 3/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8285 - loss: 0.4707 - val_accuracy: 0.8186 - val_loss: 0.5012\n",
            "Epoch 4/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8420 - loss: 0.4359 - val_accuracy: 0.8214 - val_loss: 0.4497\n",
            "Epoch 5/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8691 - loss: 0.3644 - val_accuracy: 0.8286 - val_loss: 0.5034\n",
            "Epoch 6/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8816 - loss: 0.3458 - val_accuracy: 0.8414 - val_loss: 0.4332\n",
            "Epoch 7/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8907 - loss: 0.3013 - val_accuracy: 0.8279 - val_loss: 0.5181\n",
            "Epoch 8/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8869 - loss: 0.3072 - val_accuracy: 0.8464 - val_loss: 0.4317\n",
            "Epoch 9/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9142 - loss: 0.2385 - val_accuracy: 0.8657 - val_loss: 0.4230\n",
            "Epoch 10/10\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9163 - loss: 0.2358 - val_accuracy: 0.8657 - val_loss: 0.3999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CHANGE: an error I have made in my exam, is to incorrectly answer the loss and metric of the VAE (on metric i wrote accuracy, on loss I wrote the standard formula 1/n sum (d-z)). And so for the VAE to correctly work I shall use KL Divergence as the loss function, and Mean Squared Error as the metric."
      ],
      "metadata": {
        "id": "1CE7ODEVem2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model, Input\n",
        "\n",
        "latent_dim = 2\n",
        "flat_input_dim = 4608  # output shape from convolution\n",
        "\n",
        "encoder_inputs = Input(shape=(flat_input_dim,))\n",
        "x = layers.Dense(256, activation='relu')(encoder_inputs)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "z_mean = layers.Dense(latent_dim, name='z_mean')(x)\n",
        "z_log_var = layers.Dense(latent_dim, name='z_log_var')(x)\n",
        "\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    epsilon = tf.random.normal(shape=(tf.shape(z_mean)[0], latent_dim))\n",
        "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "z = layers.Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
        "\n",
        "encoder = Model(encoder_inputs, [z_mean, z_log_var, z], name='encoder')\n",
        "\n",
        "latent_inputs = Input(shape=(latent_dim,))\n",
        "x = layers.Dense(128, activation='relu')(latent_inputs)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "decoder_outputs = layers.Dense(flat_input_dim, activation='sigmoid')(x)\n",
        "\n",
        "decoder = Model(latent_inputs, decoder_outputs, name='decoder')\n",
        "\n",
        "# VAE\n",
        "outputs = decoder(z)\n",
        "vae = Model(encoder_inputs, outputs, name='vae')\n",
        "\n",
        "class VAE(Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def train_step(self, data):\n",
        "        if isinstance(data, tuple):\n",
        "            data = data[0]\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "            reconstruction_loss = tf.reduce_mean(tf.abs(data - reconstruction))\n",
        "            kl_loss = -0.5 * tf.reduce_mean(tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1))\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        return {\n",
        "            \"loss\": total_loss,\n",
        "            \"reconstruction_loss\": reconstruction_loss,\n",
        "            \"kl_loss\": kl_loss,\n",
        "        }\n",
        "\n",
        "\n",
        "vae = VAE(encoder, decoder)\n",
        "vae.compile(optimizer='adam')\n",
        "vae.summary()\n",
        "\n",
        "conv_out = conv_model.predict(X_train)\n",
        "conv_out = conv_out.reshape(conv_out.shape[0], -1)\n",
        "print(f\"conv_out.shape:{conv_out.shape}\")\n",
        "vae.fit(conv_out, conv_out, epochs=10, batch_size=32)\n"
      ],
      "metadata": {
        "id": "dIX8pOEzthv4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        },
        "outputId": "68c821a1-3b2b-4c5e-9d43-b288f025b919"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"vae_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"vae_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ encoder (\u001b[38;5;33mFunctional\u001b[0m)            │ (\u001b[38;5;34m(None, 2)\u001b[0m, \u001b[38;5;34m(None, 2)\u001b[0m, │     \u001b[38;5;34m1,213,316\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m(None, 2)\u001b[0m)             │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder (\u001b[38;5;33mFunctional\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4608\u001b[0m)           │     \u001b[38;5;34m1,217,664\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">(None, 2)</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">(None, 2)</span>, │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,213,316</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">(None, 2)</span>)             │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4608</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,217,664</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,430,980\u001b[0m (9.27 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,430,980</span> (9.27 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,430,980\u001b[0m (9.27 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,430,980</span> (9.27 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "conv_out.shape:(5600, 4608)\n",
            "Epoch 1/10\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - kl_loss: 0.0017 - loss: 0.0986 - reconstruction_loss: 0.0969\n",
            "Epoch 2/10\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - kl_loss: 6.4180e-05 - loss: 0.0417 - reconstruction_loss: 0.0417\n",
            "Epoch 3/10\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - kl_loss: 3.8352e-05 - loss: 0.0410 - reconstruction_loss: 0.0410\n",
            "Epoch 4/10\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - kl_loss: 2.7596e-05 - loss: 0.0403 - reconstruction_loss: 0.0403\n",
            "Epoch 5/10\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - kl_loss: 2.1842e-05 - loss: 0.0399 - reconstruction_loss: 0.0399\n",
            "Epoch 6/10\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - kl_loss: 1.4182e-05 - loss: 0.0398 - reconstruction_loss: 0.0398\n",
            "Epoch 7/10\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - kl_loss: 1.1705e-05 - loss: 0.0398 - reconstruction_loss: 0.0398\n",
            "Epoch 8/10\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - kl_loss: 1.1245e-05 - loss: 0.0398 - reconstruction_loss: 0.0398\n",
            "Epoch 9/10\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - kl_loss: 1.0382e-05 - loss: 0.0398 - reconstruction_loss: 0.0398\n",
            "Epoch 10/10\n",
            "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - kl_loss: 8.0857e-06 - loss: 0.0398 - reconstruction_loss: 0.0398\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79ea2138f190>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The reconstruction loss is around 0.0339, which means the model is doing a good job recreating the input images.\n",
        "\n",
        "The KL loss is very small, so the latent space is close to a normal distribution, but it doesn't affect the total loss much."
      ],
      "metadata": {
        "id": "TJVm5axk0ljh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_sample = X_test[0:1]\n",
        "flat_input = conv_model.predict(x_sample).reshape(1, -1)\n",
        "reconstructed = vae.decoder(vae.encoder(flat_input)[2]).numpy().reshape(12, 12, 32)\n",
        "\n",
        "plt.imshow(reconstructed[:, :, 0], cmap='gray')  # Show just the first channel\n",
        "plt.axis('off')\n",
        "plt.title(\"VAE Reconstruction (channel 0)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "K7LXAj171y1N",
        "outputId": "f70dcf51-3a7f-40cb-d15b-107c55cc5f41"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}